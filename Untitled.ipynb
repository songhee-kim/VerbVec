{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def find_subset_semantic_category(listfile, df, totalN, semcategoryN, max_try=10000): \n",
    "import ast\n",
    "list1 = '/Users/songheekim/Google Drive/Primary/Projects/VerbVector/Verblists/returnedlists_4gram/50_55_55_list1.txt'\n",
    "file_id = list1.split('/')[-1].split('_list')\n",
    "file = open(list1, \"r\")\n",
    "contents = file.read()\n",
    "dic = ast.literal_eval(contents)\n",
    "verbs_matched = dic['unergative'] + dic['unaccusative'] + dic['transitive']\n",
    "print ('verb_matched', len(verbs_matched))\n",
    "\n",
    "df = pd.read_excel('/Users/songheekim/Google Drive/Primary/Projects/VerbVector/Verblists/verblist_v3.0_45gram_cleancandidatesforpermutation.xlsx')\n",
    "df = df.rename(columns={\"SemClass_Consensus\": \"SemClass\", \"AspClass_Consensus\": \"AspClass\"})\n",
    "column_to_drop = ['word', 'unerg_pb', 'unacc_pb', 'tr_pb', 'totalN_pb', 'most_frequent_pb', 'intr_g', 'tr_g', \\\n",
    "          'totalN_g', 'most_frequent_g', 'intr_google', 'trans_google', 'google1950_intrans', \\\n",
    "          'google1950_trans', 'google_5gram_intrans', 'google_5gram_trans', 'SemanticType_JB', \\\n",
    "          'SemanticType_JB_edit', 'Typicality_JB', 'SemanticType_LC', 'Typicality_LC', 'CONSENSUS_JB']\n",
    "df.drop(columns=column_to_drop, inplace=True)\n",
    "df_avail = df.loc[df['in']==1]\n",
    "print ('df_avail', df_avail.shape)\n",
    "allverbs = df_avail['Lemma'].tolist()\n",
    "print ('# of all available verbs:', len(allverbs))\n",
    "\n",
    "df['in'] = ''\n",
    "df['syn_matched']=''\n",
    "df = rearrange_col(df, 'syn_matched', 'in')\n",
    "df['in'] = np.where(df['Lemma'].isin(verbs_matched), 1, 0)\n",
    "df['matched'] = np.where(df['Lemma'].isin(verbs_matched), 1, 0)\n",
    "df.drop(columns=['Index'], inplace=True)\n",
    "\n",
    "extraN = 200 - len(verbs_matched)\n",
    "verbs_remaining = [i for i in allverbs if i not in verbs_matched]\n",
    "semclass= set(df_avail['SemClass'].tolist())\n",
    "\n",
    "semclass_all = {} #### for raw_avail\n",
    "for semcl in semclass:\n",
    "    semclass_all[semcl] = df_avail.loc[df_avail['SemClass']==semcl]['Lemma'].tolist()\n",
    "\n",
    "cols_test = ['LogFreqHAL', 'AgeofAcqsn', 'Length', 'Ortho_N', 'Phono_N', 'OLD', 'PLD', 'NPhon', 'NSyll', \\\n",
    "             'I_Mean_RT', 'I_Mean_Accuracy', 'I_NMG_Mean_RT', 'I_NMG_Mean_Accuracy', 'N2_F', 'N3_F']\n",
    "    \n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "tqdm().pandas()\n",
    "\n",
    "success_n = 0 \n",
    "nearly_good_n = 0\n",
    "for attempt_n in tqdm(range(1)):\n",
    "    verbs_extra = PopSamples(verbs_remaining, extraN)\n",
    "    verbs_final = verbs_matched + verbs_extra\n",
    "    df['in'] = np.where(df['Lemma'].isin(verbs_final), 1, 0)\n",
    "    #print (df.head())\n",
    "    df_chosen = df.loc[df['in']==1]\n",
    "    df_chosen.to_excel('~/Desktop/df_chosen.xlsx')\n",
    "    #print(df_chosen.shape)\n",
    "    semclass_chosen = {}\n",
    "    for semcl in semclass:\n",
    "        semclass_chosen[semcl] = df_chosen.loc[df_chosen['SemClass']==semcl]['Lemma'].tolist()\n",
    "        \n",
    "#     semclass_pool = {}\n",
    "#     for k, v in semclass_all.items():\n",
    "#         semclass_pool[k] = [i for i in v if i not in semclass_chosen[k]]\n",
    "    ct_sem = pd.crosstab(df_chosen.SemClass, df_chosen.SynClassNew, margins=True).sort_values(by='All', ascending=False)\n",
    "    top_label = choose_top_cat(ct_sem, 5).index.tolist()\n",
    "    #print (top_label)\n",
    "    pairs = list(itertools.combinations(top_label, 2))\n",
    "    #print (pairs)\n",
    "\n",
    "    #test_dic = {}\n",
    "    take = 1\n",
    "    result_log = []\n",
    "    for i in range(0, len(cols_test)):\n",
    "        #print (cols_test[i])\n",
    "        for p in pairs:\n",
    "            #print (p)\n",
    "            series1 = df_chosen.loc[df_chosen['SemClass']==p[0]][cols_test[i]].tolist()\n",
    "            series2 = df_chosen.loc[df_chosen['SemClass']==p[1]][cols_test[i]].tolist()\n",
    "            r=ttest_is_significant(series1, series2, equal_var=False, threshold = 0)\n",
    "            result_log.append(r)\n",
    "            take *= r\n",
    "\n",
    "    fail_n = result_log.count(0)\n",
    "    print (fail_n, ' failed out of ', len(result_log))\n",
    "    if fail_n < len(cols_test)*len(pairs) * 0.1:\n",
    "        print ('Attempt', attempt_n, ' has t-tests failed ', fail_n, 'times')\n",
    "\n",
    "    if fail_n < 6:\n",
    "        nearly_good_n += 1\n",
    "        df.to_excel('./%s_nearlygood_list%d.xlsx' %(file_id, nearly_good_n))\n",
    "\n",
    "    if take: \n",
    "        success_n += 1\n",
    "        print ('set %d found' %success_n)\n",
    "        for k in sorted(semclass_chosen, key=lambda k: len(semclass_chosen[k]), reverse=True):\n",
    "            print (k, len(semclass_chosen[k]))\n",
    "#         for k, v in semclass_chosen_ordered.items():\n",
    "#             print (k, len(v))\n",
    "        df.to_excel('./%s_list%d.xlsx' %(file_id, success_n))\n",
    "\n",
    "        #print (success_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
