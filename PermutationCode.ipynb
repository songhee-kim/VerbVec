{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_col(dataframe, col_to_move, reference_col, right=True):\n",
    "    col_list = dataframe.columns.values.tolist()\n",
    "    col_list2 = [x for x in col_list if x != col_to_move]\n",
    "    reference_idx = col_list2.index(reference_col)\n",
    "    if right==True:\n",
    "        col_list3 = []\n",
    "        for y in col_list2:\n",
    "            col_list3.append(y)\n",
    "            if y == reference_col:\n",
    "                col_list3.append(col_to_move)\n",
    "        return dataframe[col_list3]\n",
    "    else:\n",
    "        col_list3 = []\n",
    "        for y in col_list2:\n",
    "            col_list3.append(y)\n",
    "            if y == reference_col:\n",
    "                col_list3.insert(-2, col_to_move)\n",
    "        return  dataframe[col_list3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PopSamples(pool, num_subset):\n",
    "    np.random.shuffle(pool)\n",
    "    return pool[:num_subset]\n",
    "\n",
    "def ttest_is_significant (series1, series2, threshold=0.05, equal_var=False):\n",
    "    #statistic = stats.ttest_ind(series1, series2, equal_var=equal_var).statistic\n",
    "    #pvalue = stats.ttest_ind(series1, series2, equal_var=equal_var).pvalue\n",
    "    ret = stats.ttest_ind(series1, series2, equal_var=equal_var)\n",
    "    #print (ret.pvalue)\n",
    "    if ret.pvalue > threshold: \n",
    "        result = 1  # pass, i.e, 'Insignificant'\n",
    "    else:\n",
    "        result = 0  # fail, i.e, 'Significantly different distribution'\n",
    "    #print (result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = raw.sort_values(by=['in', 'SynClassNew', 'GrandIndex'], ascending=[False, False, True])\n",
    "#df = rearrange_col(df, 'In', 'SynClassNew')\n",
    "\n",
    "#### copy index column to access them just like any other column\n",
    "# df['word'] = df.index\n",
    "# df = rearrange_col(df, 'word', 'GrandIndex', right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c90749c1aee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m cols_to_test = ['LogFreqHAL', 'AgeofAcqsn', 'Length', 'Ortho_N', 'Phono_N',\\\n\u001b[1;32m      3\u001b[0m                 \u001b[0;34m'OLD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PLD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NPhon'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NSyll'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'I_Mean_RT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'I_Mean_Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'I_NMG_Mean_RT'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 'I_NMG_Mean_Accuracy', 'N2_F', 'N3_F'] ##Note: Concreteness is not included\n\u001b[1;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols_to_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "colnames = list(df.columns.values)\n",
    "cols_to_test = ['LogFreqHAL', 'AgeofAcqsn', 'Length', 'Ortho_N', 'Phono_N',\\\n",
    "                'OLD', 'PLD', 'NPhon', 'NSyll', 'I_Mean_RT', 'I_Mean_Accuracy', 'I_NMG_Mean_RT', \\\n",
    "                'I_NMG_Mean_Accuracy', 'N2_F', 'N3_F'] ##Note: Concreteness is not included\n",
    "len(cols_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_in:        348\n",
      "df_synmatch:  166\n",
      "df_freqmatch: 124\n",
      "unergative:   36\n",
      "unaccusative: 46\n",
      "transitive:   42\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('/Users/songheekim/Google Drive/Primary/Projects/VerbVector/Verblists/List320.xlsx', index_col='Lemma')\n",
    "df_in = df[df['in']==1]\n",
    "df_synmatch = df_in[df_in['syn_matched']==1]\n",
    "df_freqmatch = df_in[df_in['freq_matched']==1]\n",
    "unergative = df_freqmatch[df_freqmatch['SynClass'] =='unergative']\n",
    "unaccusative = df_freqmatch[df_freqmatch['SynClass'] =='unaccusative']\n",
    "transitive = df_freqmatch[df_freqmatch['SynClass'] =='transitive']\n",
    "\n",
    "print ('df_in:       ', df_in.shape[0])\n",
    "print ('df_synmatch: ', df_synmatch.shape[0])\n",
    "print ('df_freqmatch:', df_freqmatch.shape[0])\n",
    "print ('unergative:  ', unergative.shape[0])\n",
    "print ('unaccusative:', unaccusative.shape[0])\n",
    "print ('transitive:  ', transitive.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_in:        321\n",
      "df_synmatch:  157\n",
      "df_freqmatch: 117\n",
      "unergative:   34\n",
      "unaccusative: 45\n",
      "transitive:   38\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('/Users/songheekim/Google Drive/Primary/Projects/VerbVector/Verblists/List320.xlsx', index_col='Lemma')\n",
    "df_in = df[df['in']==1]\n",
    "df_synmatch = df_in[df_in['syn_matched']==1]\n",
    "df_freqmatch = df_in[df_in['freq_matched']==1]\n",
    "unergative = df_freqmatch[df_freqmatch['SynClass'] =='unergative']\n",
    "unaccusative = df_freqmatch[df_freqmatch['SynClass'] =='unaccusative']\n",
    "transitive = df_freqmatch[df_freqmatch['SynClass'] =='transitive']\n",
    "\n",
    "print ('df_in:       ', df_in.shape[0])\n",
    "print ('df_synmatch: ', df_synmatch.shape[0])\n",
    "print ('df_freqmatch:', df_freqmatch.shape[0])\n",
    "print ('unergative:  ', unergative.shape[0])\n",
    "print ('unaccusative:', unaccusative.shape[0])\n",
    "print ('transitive:  ', transitive.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_freqmatch: (117, 43)\n",
      "unergative: 34\n",
      "unaccusative: 45\n",
      "transitive: 38\n",
      "==== LogFreqHAL\n",
      "==== AgeofAcqsn\n",
      "==== Length\n",
      "==== Ortho_N\n",
      "==== Phono_N\n",
      "==== OLD\n",
      "==== PLD\n",
      "==== NPhon\n",
      "==== NSyll\n",
      "==== I_Mean_RT\n",
      "==== I_Mean_Accuracy\n",
      "==== I_NMG_Mean_RT\n",
      "==== I_NMG_Mean_Accuracy\n",
      "==== N2_F\n",
      "==== N3_F\n",
      "\n",
      "Syntactic test finished!\n"
     ]
    }
   ],
   "source": [
    "############ CHECK IF SYNTACTIC CATEGORIES ARE MATCHED FOR LOW LEVEL QUALITIES \n",
    "syncat = ['unergative', 'unaccusative', 'transitive']\n",
    "print ('df_freqmatch:', df_freqmatch.shape)\n",
    "\n",
    "print ('unergative:', unergative.shape[0])\n",
    "print ('unaccusative:', unaccusative.shape[0])\n",
    "print ('transitive:', transitive.shape[0])\n",
    "\n",
    "cols_test = ['LogFreqHAL', 'AgeofAcqsn', 'Length', 'Ortho_N', 'Phono_N', 'OLD', 'PLD', 'NPhon', 'NSyll', \\\n",
    "            'I_Mean_RT', 'I_Mean_Accuracy', 'I_NMG_Mean_RT', 'I_NMG_Mean_Accuracy', 'N2_F', 'N3_F']\n",
    "pairs1 = [('unergative', 'unaccusative'), ('unaccusative', 'transitive'), ('transitive', 'unergative')]\n",
    "\n",
    "for c in cols_test:\n",
    "    print ('====', c)\n",
    "    for p in pairs1:\n",
    "        x = ttest_is_significant(df_freqmatch.loc[df_freqmatch['SynClass']==p[0]][c].tolist(), \\\n",
    "                         df_freqmatch.loc[df_freqmatch['SynClass']==p[1]][c].tolist(), \\\n",
    "                         threshold=0.05, equal_var=False)\n",
    "        if x == 0:\n",
    "            print (c, p, 'p < 0.05')\n",
    "            print ('--', p[0], round(df_freqmatch.loc[df_freqmatch['SynClass']==p[0]][c].mean(),2))\n",
    "            print ('--', p[1], round(df_freqmatch.loc[df_freqmatch['SynClass']==p[1]][c].mean(),2))\n",
    "print ('\\nSyntactic test finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = transitive.sort_values(by=['LogFreqHAL'], ascending=False)[:20].index.tolist()\n",
    "l2 = transitive.sort_values(by=['N3_F'], ascending=True)[:20].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hit',\n",
       " 'build',\n",
       " 'hate',\n",
       " 'carry',\n",
       " 'throw',\n",
       " 'contain',\n",
       " 'solve',\n",
       " 'delete',\n",
       " 'destroy',\n",
       " 'deny',\n",
       " 'earn',\n",
       " 'hire',\n",
       " 'steal',\n",
       " 'restore',\n",
       " 'confirm',\n",
       " 'deliver',\n",
       " 'construct',\n",
       " 'enhance',\n",
       " 'invite',\n",
       " 'preserve']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wag',\n",
       " 'delete',\n",
       " 'owe',\n",
       " 'loathe',\n",
       " 'abandon',\n",
       " 'deny',\n",
       " 'invite',\n",
       " 'enrich',\n",
       " 'solve',\n",
       " 'praise',\n",
       " 'earn',\n",
       " 'lengthen',\n",
       " 'inflate',\n",
       " 'revive',\n",
       " 'evade',\n",
       " 'dislike',\n",
       " 'hit',\n",
       " 'weaken',\n",
       " 'celebrate',\n",
       " 'hire']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hit', 'solve', 'delete', 'deny', 'earn', 'hire', 'invite']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in l1 if i in l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsyn = df_synmatch.reset_index() ### 'Lemma' is no longer index\n",
    "cols_array = ['Lemma', 'GrandIndex', 'SynClass', 'in', 'LogFreqHAL', 'AgeofAcqsn', 'Length', 'Ortho_N', 'Phono_N',\\\n",
    "                'OLD', 'PLD', 'NPhon', 'NSyll', 'I_Mean_RT', 'I_Mean_Accuracy', 'I_NMG_Mean_RT', \\\n",
    "                'I_NMG_Mean_Accuracy', 'N2_F', 'N3_F'] ##Concreteness, Percentage_dom_PoS are not includeed\n",
    "dfsyn_array = dfsyn[cols_array]\n",
    "\n",
    "\n",
    "#### select for df['in']=1\n",
    "array_unergative = df_to_array.loc[(df_to_array['SynClassNew']=='unergative') & (df_to_array['in']==1)]\n",
    "array_unaccusative = df_to_array.loc[(df_to_array['SynClassNew']=='unaccusative') & (df_to_array['in']==1)]\n",
    "array_transitive = df_to_array.loc[(df_to_array['SynClassNew']=='transitive') & (df_to_array['in']==1)]\n",
    "#array_transitive_all = df_to_array[df_to_array['SynClassNew'].isin(['transitive', '?transitive']) & (df_to_array['In']==1)]\n",
    "\n",
    "#### drop all non-numeral columns except 'Lemma', and give a new index (for no missing index)\n",
    "array_unergative2 = array_unergative.reset_index(drop=True).drop(columns=['SynClassNew', 'GrandIndex', 'in'])\n",
    "array_unaccusative2 = array_unaccusative.reset_index(drop=True).drop(columns=['SynClassNew', 'GrandIndex', 'in'])\n",
    "array_transitive2 = array_transitive.reset_index(drop=True).drop(columns=['SynClassNew', 'GrandIndex', 'in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subset(unerg_N, unacc_N, trans_N, max_try=100, threshold=0.05):\n",
    "    ''' this function takes sample sizes of desired output, # of maximum trials, and p value\n",
    "        and returns a perfect sample that satisfies the conditions, if any.\n",
    "        unerg_N = size of group 1 \n",
    "        unacc_N = size of group 2 \n",
    "        trans_N = size of group 3 ''' ##todo: modify the function that it takes the dataframe as well\n",
    "    \n",
    "    from tqdm.notebook import tqdm as tqdm\n",
    "    tqdm().pandas()\n",
    "\n",
    "    column_n = nd_g1.shape[1]\n",
    "    successful_set = []\n",
    "\n",
    "    # make a number of rows (=# of verbs) into a list \n",
    "    g1_pool = np.arange(nd_g1.shape[0]) #nd_g1 = 2D numpy array of Group 1, g1_pool=its row number as a list\n",
    "    g2_pool = np.arange(nd_g2.shape[0])\n",
    "    g3_pool = np.arange(nd_g3.shape[0])\n",
    "\n",
    "    for attempt_n in tqdm(range(max_try)):\n",
    "    #for attempt_n in range(max_try):\n",
    "        #print ('Attempt', attempt_n)\n",
    "\n",
    "        #(1) random select N items in nd_g1, nd_g2 and nd_g3\n",
    "        g1_index = PopSamples(g1_pool, g1_N) ##i.e., choose 80 int in [0,,85] (when #row=86) \n",
    "        g2_index = PopSamples(g2_pool, g2_N) ##i.e., choose 80 int in [0,,151] (when #row=152) \n",
    "        g3_index = PopSamples(g3_pool, g3_N) ##i.e., choose 80 int in [0,,120] (when #row=121) \n",
    "\n",
    "        nd_g1_sel = nd_g1[g1_index] #subset arrays\n",
    "        nd_g2_sel = nd_g2[g2_index]\n",
    "        nd_g3_sel = nd_g3[g3_index]\n",
    "\n",
    "        #(2) iterate over 16 columns, perform t-tests\n",
    "        test_dic = {}\n",
    "        take = 1\n",
    "        logfreq_g1g2 = round(stats.ttest_ind(nd_g1_sel[:,0], nd_g2_sel[:,0], equal_var=False).pvalue, 2)\n",
    "        logfreq_g2g3 = round(stats.ttest_ind(nd_g2_sel[:,0], nd_g3_sel[:,0], equal_var=False).pvalue, 2)\n",
    "        logfreq_g1g3 = round(stats.ttest_ind(nd_g1_sel[:,0], nd_g3_sel[:,0], equal_var=False).pvalue, 2)\n",
    "        \n",
    "        \n",
    "        for i in range(1, column_n):\n",
    "            #print (i) #print (header_d[i])\n",
    "            #test_dic[i] = {}\n",
    "            #test_dic[i]['g1-g2'] = ttest_is_significant(nd_g1_sel[:,i], nd_g2_sel[:,i], threshold=threshold)\n",
    "            #test_dic[i]['g2-g3'] = ttest_is_significant(nd_g2_sel[:,i], nd_g3_sel[:,i], threshold=threshold)\n",
    "            #test_dic[i]['g1-g3'] = ttest_is_significant(nd_g1_sel[:,i], nd_g3_sel[:,i], threshold=threshold)\n",
    "            #take *= test_dic[i]['g1-g2']*test_dic[i]['g2-g3']*test_dic[i]['g1-g3']\n",
    "            g1g2 = ttest_is_significant(nd_g1_sel[:,i], nd_g2_sel[:,i], threshold=threshold)\n",
    "            g2g3 = ttest_is_significant(nd_g2_sel[:,i], nd_g3_sel[:,i], threshold=threshold)\n",
    "            g1g3 = ttest_is_significant(nd_g1_sel[:,i], nd_g3_sel[:,i], threshold=threshold)\n",
    "            take *= g1g2*g2g3*g1g3\n",
    "            \n",
    "            #test_dic[i]['pass'] = take   ###take==1 by default; becomes 0 if at least 1 failed test exists\n",
    "            #test_dic['pass']=take\n",
    "        \n",
    "        if take:\n",
    "            #test_dic['unergative_index'] = g1_index\n",
    "            #test_dic['unaccusative_index'] = g2_index\n",
    "            #test_dic['transitive_index'] = g3_index\n",
    "            test_dic['unergative'] = [unerg_lemma_d[i] for i in g1_index]\n",
    "            test_dic['unaccusative'] = [unacc_lemma_d[i] for i in g2_index]\n",
    "            test_dic['transitive'] = [trans_lemma_d[i] for i in g3_index]\n",
    "            test_dic['logFreq_unerg_unacc'] = logfreq_g1g2\n",
    "            test_dic['logFreq_unacc_trans'] = logfreq_g2g3\n",
    "            test_dic['logFreq_unerg_trans'] = logfreq_g1g3\n",
    "            successful_set.append(test_dic)\n",
    "            \n",
    "            listN = len(successful_set)\n",
    "            print ('set found')\n",
    "            \n",
    "            with open('/Users/songheekim/Google Drive/Primary/Projects/VerbVec/fmatched_%d_%d_%d_list%d.txt' %(g1_N, g2_N, g3_N, listN), 'w') as f:\n",
    "                print (test_dic, file=f)\n",
    "            \n",
    "            break\n",
    "            #print (g1_index, g2_index, g3_index)\n",
    "            \n",
    "\n",
    "    print(g1_N, g2_N, g3_N, 'has found', len(successful_set), 'sets!')\n",
    "    #return successful_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### remove word with NaN if any\n",
    "# for c in cols_to_test:\n",
    "#     if df_in.loc[pd.isna(df[c])].shape[0] !=0: ### find any columns that contain NaN\n",
    "#         print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### select for df['in']=1\n",
    "# array_unergative = df_to_array.loc[(df_to_array['SynClassNew']=='unergative') & (df_to_array['in']==1)]\n",
    "# array_unaccusative = df_to_array.loc[(df_to_array['SynClassNew']=='unaccusative') & (df_to_array['in']==1)]\n",
    "# array_transitive = df_to_array.loc[(df_to_array['SynClassNew']=='transitive') & (df_to_array['in']==1)]\n",
    "# #array_transitive_all = df_to_array[df_to_array['SynClassNew'].isin(['transitive', '?transitive']) & (df_to_array['In']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####make dictionaries; i.e., from index (=array row number) to lemma\n",
    "unerg_lemma_d = dict(zip(array_unergative2.index, array_unergative2.Lemma))\n",
    "unacc_lemma_d = dict(zip(array_unaccusative2.index, array_unaccusative2.Lemma))\n",
    "trans_lemma_d = dict(zip(array_transitive2.index, array_transitive2.Lemma))\n",
    "\n",
    "#### check if the results are correct\n",
    "# for i in range(len(unerg_lemma_d.keys())):\n",
    "#     check = unerg_lemma_d[i] == array_unergative2.loc[i,'Lemma']\n",
    "#     if not check: \n",
    "#         print ('unergative', i, 'th member needs check')\n",
    "# for i in range(len(unacc_lemma_d.keys())):\n",
    "#     check = unacc_lemma_d[i] == array_unaccusative2.loc[i,'Lemma']\n",
    "#     if not check: \n",
    "#         print ('unaccusative', i, 'th member needs check')\n",
    "# for i in range(len(trans_lemma_d.keys())):\n",
    "#     check = trans_lemma_d[i] == array_transitive2.loc[i,'Lemma']\n",
    "#     if not check: \n",
    "#         print ('transitive', i, 'th member needs check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### make a dictionary of header: i.e., column position to header \n",
    "array_unergative2_copy = array_unergative2.copy().drop(columns='Lemma')\n",
    "header = array_unergative2_copy.columns.tolist() #i.e., ['LogFreqHAL', 'AgeofAcqsn', .. 'N2_F', 'N3_F']\n",
    "header_d = {index: key for index, key in enumerate(header)}\n",
    "\n",
    "###### drop Lemma so that only numerals are kept (g1 = unergative, g2 = unaccusative, g3 = transitive)\n",
    "nd_g1 = array_unergative2.drop(columns=['Lemma']).to_numpy()\n",
    "nd_g2 = array_unaccusative2.drop(columns=['Lemma']).to_numpy()\n",
    "nd_g3 = array_transitive2.drop(columns=['Lemma']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('nd_g1 shape:', nd_g1.shape)\n",
    "print ('nd_g2 shape:', nd_g2.shape)\n",
    "print ('nd_g3 shape:', nd_g3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('nd_g1 shape:', nd_g1.shape)\n",
    "print ('nd_g2 shape:', nd_g2.shape)\n",
    "print ('nd_g3 shape:', nd_g3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_subset(50, 50, 50, max_try=5000000, threshold=0.05)\n",
    "\n",
    "for unergN in range(50, 60):\n",
    "    for unaccN in range(55, 65):\n",
    "        for transN in range(55, 65):\n",
    "            print (unergN, unaccN, transN)\n",
    "            find_subset(unergN, unaccN, transN, max_try=5000000, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('/jbinder/work/songkim/Projects/VerbVector/returnedlists/%d_%d_%d_list%d.txt' %(g1_N, g2_N, g3_N, listN), 'w') as f:\n",
    "                print (test_dic, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#header_d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_subset(nd_g1.shape[0], nd_g2.shape[0], nd_g3.shape[0], max_try=1, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_subset(10, 10, 10, max_try=100, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_subset(30, 30, 30, max_try=500, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_subset(70, 70, 50, max_try=500000, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_subset(60, 80, 70, max_try=1000000, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_608070_unerg1 = array_unergative2.iloc[set_608070['set1']['unergative_index'], ]\n",
    "# set_608070_unacc1 = array_unaccusative2.iloc[set_608070['set1']['unaccusative_index'], ]\n",
    "# set_608070_trans1 = array_transitive2.iloc[set_608070['set1']['transitive_index'], ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_raw_data_distribution(n):\n",
    "    import matplotlib.pyplot as plt\n",
    "    #plt.plot(np.arange(nd_g1.shape[0]),nd_g1[:,0], 'b.')\n",
    "    fig, axis = plt.subplots(3)\n",
    "    fig.subplots_adjust(bottom=0, top=1.5, hspace=0.5)\n",
    "    axis[0].hist(nd_g1[:,n])\n",
    "    axis[0].set_title(header_d[n]+\": unergative\")\n",
    "    axis[1].hist(nd_g2[:,n])\n",
    "    axis[1].set_title(header_d[n]+\": unaccusative\")\n",
    "    axis[2].hist(nd_g3[:,n])\n",
    "    axis[2].set_title(header_d[n]+\": transitive\")\n",
    "    #print (header_d[n])\n",
    "    \n",
    "for i in range(15):\n",
    "    show_raw_data_distribution(i)\n",
    "#show_raw_data_distribution(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
