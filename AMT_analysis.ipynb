{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "%pprint off\n",
    "savepath = '/Users/songkim/GoogleDrive/Primary/Projects/VerbVector/AMT/html/experiments/ratings2/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_col(dataframe, col_to_move, reference_col, right=True):\n",
    "    col_list = dataframe.columns.values.tolist()\n",
    "    col_list2 = [x for x in col_list if x != col_to_move]\n",
    "    reference_idx = col_list2.index(reference_col)\n",
    "    if right==True:\n",
    "        col_list3 = []\n",
    "        for y in col_list2:\n",
    "            col_list3.append(y)\n",
    "            if y == reference_col:\n",
    "                col_list3.append(col_to_move)\n",
    "        return dataframe[col_list3]\n",
    "    else:\n",
    "        col_list3 = []\n",
    "        for y in col_list2:\n",
    "            col_list3.append(y)\n",
    "            if y == reference_col:\n",
    "                col_list3.insert(-2, col_to_move)\n",
    "        return  dataframe[col_list3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/Users/songkim/GoogleDrive/Primary/Projects/VerbVector/AMT/html/experiments/ratings2/results/results_clean_0813.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before catch-based rejection: (4335, 20)\n",
      "after catch-based rejection: (3802, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stim_id</th>\n",
       "      <th>stim</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>response</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>RT</th>\n",
       "      <th>buttonpress</th>\n",
       "      <th>turkcode</th>\n",
       "      <th>subject_num</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>occupation</th>\n",
       "      <th>results_id</th>\n",
       "      <th>catch_subject_id</th>\n",
       "      <th>catch_response</th>\n",
       "      <th>correctN</th>\n",
       "      <th>badsubject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>laugh</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0, 0, 3, 0, 0, 1, 5, 6, 2, 3, 3, 6, 2, 0, ...</td>\n",
       "      <td>2021-05-25 16:26:41</td>\n",
       "      <td>2021-05-25 16:35:15</td>\n",
       "      <td>[10451, 2940, 2319, 3999, 2779, 3110, 6525, 75...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, ...</td>\n",
       "      <td>8545510</td>\n",
       "      <td>A3I9XLIHPPWPN1</td>\n",
       "      <td>f</td>\n",
       "      <td>57</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Dataanalystadministrationassistant</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>295</td>\n",
       "      <td>see</td>\n",
       "      <td>2</td>\n",
       "      <td>[6, 3, 0, 1, 1, 2, 0, 4, 0, 1, 0, 3, 3, 0, 0, ...</td>\n",
       "      <td>2021-05-25 16:29:38</td>\n",
       "      <td>2021-05-25 16:36:24</td>\n",
       "      <td>[4024, 9148, 2726, 5130, 5199, 3487, 2790, 432...</td>\n",
       "      <td>[1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2727964</td>\n",
       "      <td>A2CWJRAEFZ44HU</td>\n",
       "      <td>m</td>\n",
       "      <td>36</td>\n",
       "      <td>14.0</td>\n",
       "      <td>nursingassistantihelpoutpatientsandstaffinahos...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>214</td>\n",
       "      <td>flatten</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 0, 0, 0, 5, 3, 1, 1, 3, 2, 0, 5, 0, 1, 4, ...</td>\n",
       "      <td>2021-05-25 16:26:58</td>\n",
       "      <td>2021-05-25 16:36:47</td>\n",
       "      <td>[4432, 2912, 2592, 3640, 7976, 6904, 5368, 608...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3205581</td>\n",
       "      <td>A7ERZELTAMWL5</td>\n",
       "      <td>m</td>\n",
       "      <td>70</td>\n",
       "      <td>18.0</td>\n",
       "      <td>PatrolofficerIridearoundaresidentialcomplextoc...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>calm</td>\n",
       "      <td>5</td>\n",
       "      <td>[4, 0, 0, 0, 3, 0, 0, 1, 4, 0, 5, 0, 4, 2, 2, ...</td>\n",
       "      <td>2021-05-25 16:28:07</td>\n",
       "      <td>2021-05-25 16:38:09</td>\n",
       "      <td>[4142, 2349, 7257, 8933, 4802, 3372, 3349, 830...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, ...</td>\n",
       "      <td>1247441</td>\n",
       "      <td>A2LF84L3K71GR2</td>\n",
       "      <td>f</td>\n",
       "      <td>38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>RestaurantSupervisor</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>jump</td>\n",
       "      <td>6</td>\n",
       "      <td>[3, 0, 0, 0, 0, 1, 0, 3, 6, 3, 0, 0, 0, 6, 0, ...</td>\n",
       "      <td>2021-05-25 16:29:58</td>\n",
       "      <td>2021-05-25 16:45:19</td>\n",
       "      <td>[9500, 3180, 3371, 90941, 4762, 8544, 6685, 40...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8286749</td>\n",
       "      <td>A1VSHM4NLZ705D</td>\n",
       "      <td>m</td>\n",
       "      <td>41</td>\n",
       "      <td>12.0</td>\n",
       "      <td>retail</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  stim_id     stim  subject_id  \\\n",
       "0   1      159    laugh           1   \n",
       "1   2      295      see           2   \n",
       "2   3      214  flatten           3   \n",
       "4   5      262     calm           5   \n",
       "5   6        7     jump           6   \n",
       "\n",
       "                                            response                start  \\\n",
       "0  [1, 0, 0, 3, 0, 0, 1, 5, 6, 2, 3, 3, 6, 2, 0, ...  2021-05-25 16:26:41   \n",
       "1  [6, 3, 0, 1, 1, 2, 0, 4, 0, 1, 0, 3, 3, 0, 0, ...  2021-05-25 16:29:38   \n",
       "2  [3, 0, 0, 0, 5, 3, 1, 1, 3, 2, 0, 5, 0, 1, 4, ...  2021-05-25 16:26:58   \n",
       "4  [4, 0, 0, 0, 3, 0, 0, 1, 4, 0, 5, 0, 4, 2, 2, ...  2021-05-25 16:28:07   \n",
       "5  [3, 0, 0, 0, 0, 1, 0, 3, 6, 3, 0, 0, 0, 6, 0, ...  2021-05-25 16:29:58   \n",
       "\n",
       "                   end                                                 RT  \\\n",
       "0  2021-05-25 16:35:15  [10451, 2940, 2319, 3999, 2779, 3110, 6525, 75...   \n",
       "1  2021-05-25 16:36:24  [4024, 9148, 2726, 5130, 5199, 3487, 2790, 432...   \n",
       "2  2021-05-25 16:36:47  [4432, 2912, 2592, 3640, 7976, 6904, 5368, 608...   \n",
       "4  2021-05-25 16:38:09  [4142, 2349, 7257, 8933, 4802, 3372, 3349, 830...   \n",
       "5  2021-05-25 16:45:19  [9500, 3180, 3371, 90941, 4762, 8544, 6685, 40...   \n",
       "\n",
       "                                         buttonpress  turkcode  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, ...   8545510   \n",
       "1  [1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   2727964   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   3205581   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, ...   1247441   \n",
       "5  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   8286749   \n",
       "\n",
       "      subject_num gender  age education  \\\n",
       "0  A3I9XLIHPPWPN1      f   57      18.0   \n",
       "1  A2CWJRAEFZ44HU      m   36      14.0   \n",
       "2   A7ERZELTAMWL5      m   70      18.0   \n",
       "4  A2LF84L3K71GR2      f   38      12.0   \n",
       "5  A1VSHM4NLZ705D      m   41      12.0   \n",
       "\n",
       "                                          occupation  results_id  \\\n",
       "0                 Dataanalystadministrationassistant           1   \n",
       "1  nursingassistantihelpoutpatientsandstaffinahos...           2   \n",
       "2  PatrolofficerIridearoundaresidentialcomplextoc...           3   \n",
       "4                               RestaurantSupervisor           5   \n",
       "5                                             retail           6   \n",
       "\n",
       "   catch_subject_id   catch_response  correctN badsubject  \n",
       "0                 1  [0, 6, 0, 6, 6]         4          N  \n",
       "1                 2  [0, 6, 0, 6, 6]         4          N  \n",
       "2                 3  [0, 6, 0, 6, 6]         4          N  \n",
       "4                 5  [0, 6, 0, 6, 6]         4          N  \n",
       "5                 6  [0, 6, 0, 6, 6]         4          N  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### PART1: CALCULATE SUBJECT-TO-GROUP CORRELATION PER HIT\n",
    "res = pd.read_csv(fpath, converters={'response': eval, 'RT': eval, 'buttonpress': eval, 'catch_response': eval})\n",
    "#res.sort_values(by=['stim_id', 'id'], inplace=True)\n",
    "print('before catch-based rejection:', res.shape)\n",
    "res.tail()\n",
    "\n",
    "######################### check number of responses per lemma\n",
    "# for i in set(res['stim_id']): \n",
    "#     df = res.loc[res['stim_id']==i]\n",
    "#     print (i, df.iloc[1,].stim, df.shape[0])\n",
    "\n",
    "########################## convert N/A to 0 \n",
    "res['catch_response_upd'] = res['catch_response'].apply(lambda x: [int(0) if i=='7' else int(i) for i in x])\n",
    "res['response_upd'] = res['response'].apply(lambda x: [int(0) if i=='7' else int(i) for i in x])\n",
    "\n",
    "res = rearrange_col(res, 'catch_response_upd', 'catch_response')\n",
    "res = rearrange_col(res, 'response_upd', 'response')\n",
    "res\n",
    "\n",
    "res.drop(columns=['catch_response', 'response'], inplace=True)\n",
    "res.rename(columns={'response_upd': 'response', 'catch_response_upd':'catch_response'}, inplace=True)\n",
    "\n",
    "######################### drop bad subjects\n",
    "res = res.loc[res['badsubject']=='N', ]\n",
    "print ('after catch-based rejection:', res.shape)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### extract \"live\" responses\n",
    "# live = res.loc[res['stim_id']==1]\n",
    "\n",
    "# response_n = len(res.iloc[0][\"response\"])\n",
    "# column = []\n",
    "# for i in range(1, response_n+1):\n",
    "#     column.append('q'+str(i))  ##### column = ['q1', 'q2', ... 'q72']\n",
    "\n",
    "# live_responses = pd.DataFrame(live.response.tolist(), columns=column).astype(int)\n",
    "\n",
    "# savepath = '/Users/songkim/GoogleDrive/Primary/Projects/VerbVector/AMT/html/experiments/ratings2/results'\n",
    "# live_responses.to_csv(savepath+ '/live_reponses.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### create an average dict ###################### \n",
    "del avg_df\n",
    "stim_id_n = len(set(res['stim_id']))  ###i.e., 320\n",
    "\n",
    "response_n = len(res.iloc[0][\"response\"])\n",
    "column = []\n",
    "for i in range(1, response_n+1):\n",
    "    column.append('q'+str(i))  ##### column = ['q1', 'q2', ... 'q72']\n",
    "\n",
    "avg_dict = {}\n",
    "for i in range(1, stim_id_n+1):\n",
    "    df = res.loc[res['stim_id']==i, ]\n",
    "    df_responses = pd.DataFrame(df.response.tolist(), columns=column).astype(int)\n",
    "    avg = list(df_responses.mean())\n",
    "    avg = [round(i,3) for i in avg]\n",
    "#     print (df.shape)\n",
    "#     print (df_responses.shape)\n",
    "\n",
    "    avg_dict[i] = {'stim': df.iloc[0]['stim'], 'subject_ids': df['subject_id'].values.tolist(), \n",
    "                  'response_N': df.shape[0], 'avg_rating': avg}\n",
    "avg_df = pd.DataFrame.from_dict(avg_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3802, 20)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avg_df[avg_df['stim']=='affect']['avg_rating'].tolist()\n",
    "# for k, v in avg_dict.items():\n",
    "#     print (v['stim'], v['response_N'])\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stim_id</th>\n",
       "      <th>stim</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>response</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>RT</th>\n",
       "      <th>buttonpress</th>\n",
       "      <th>turkcode</th>\n",
       "      <th>subject_num</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>occupation</th>\n",
       "      <th>results_id</th>\n",
       "      <th>catch_subject_id</th>\n",
       "      <th>catch_response</th>\n",
       "      <th>correctN</th>\n",
       "      <th>badsubject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4329</td>\n",
       "      <td>4330</td>\n",
       "      <td>114</td>\n",
       "      <td>build</td>\n",
       "      <td>1292</td>\n",
       "      <td>[6, 0, 0, 3, 4, 0, 1, 6, 5, 2, 3, 6, 0, 0, 1, ...</td>\n",
       "      <td>2021-08-12 22:53:52</td>\n",
       "      <td>2021-08-12 23:02:54</td>\n",
       "      <td>[4871, 7642, 3484, 6609, 7112, 5096, 9510, 492...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5192660</td>\n",
       "      <td>A1ZVJG3BKYHJWN</td>\n",
       "      <td>f</td>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "      <td>retailstorecashier</td>\n",
       "      <td>3776</td>\n",
       "      <td>1292</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4330</td>\n",
       "      <td>4331</td>\n",
       "      <td>103</td>\n",
       "      <td>shorten</td>\n",
       "      <td>1293</td>\n",
       "      <td>[5, 5, 5, 5, 5, 6, 4, 6, 6, 5, 4, 3, 4, 4, 4, ...</td>\n",
       "      <td>2021-08-12 23:06:49</td>\n",
       "      <td>2021-08-12 23:40:48</td>\n",
       "      <td>[667924, 14420, 20586, 4278, 2270, 6312, 9264,...</td>\n",
       "      <td>[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2285767</td>\n",
       "      <td>APG9EK6P41THO</td>\n",
       "      <td>m</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3777</td>\n",
       "      <td>1293</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4331</td>\n",
       "      <td>4332</td>\n",
       "      <td>243</td>\n",
       "      <td>discover</td>\n",
       "      <td>1294</td>\n",
       "      <td>[3, 5, 4, 5, 4, 5, 4, 4, 5, 4, 5, 5, 4, 5, 5, ...</td>\n",
       "      <td>2021-08-12 23:37:43</td>\n",
       "      <td>2021-08-12 23:47:34</td>\n",
       "      <td>[1992, 1873, 1567, 3326, 2023, 3199, 1328, 270...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1553234</td>\n",
       "      <td>A4SQSL2ZCEU1</td>\n",
       "      <td>f</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3778</td>\n",
       "      <td>1294</td>\n",
       "      <td>[4, 6, 0, 6, 6]</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4333</td>\n",
       "      <td>4334</td>\n",
       "      <td>198</td>\n",
       "      <td>decrease</td>\n",
       "      <td>210</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 5, 0, 4, 1, ...</td>\n",
       "      <td>2021-08-13 03:32:09</td>\n",
       "      <td>2021-08-13 03:37:55</td>\n",
       "      <td>[1976, 4112, 2681, 2408, 2120, 7560, 8361, 344...</td>\n",
       "      <td>[1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>8451568</td>\n",
       "      <td>A2LV5432PV1S39</td>\n",
       "      <td>m</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>DeputyCourtClerk</td>\n",
       "      <td>3780</td>\n",
       "      <td>210</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4334</td>\n",
       "      <td>4335</td>\n",
       "      <td>190</td>\n",
       "      <td>suffocate</td>\n",
       "      <td>354</td>\n",
       "      <td>[2, 0, 1, 3, 0, 0, 0, 3, 3, 3, 2, 0, 3, 4, 3, ...</td>\n",
       "      <td>2021-08-12 12:43:47</td>\n",
       "      <td>2021-08-13 10:28:09</td>\n",
       "      <td>[10243, 6059, 10749, 7117, 21965, 5991, 5651, ...</td>\n",
       "      <td>[1, 1, 3, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, ...</td>\n",
       "      <td>2647805</td>\n",
       "      <td>APZQ9ADUXTS7N</td>\n",
       "      <td>f</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3781</td>\n",
       "      <td>354</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  stim_id       stim  subject_id  \\\n",
       "4329  4330      114      build        1292   \n",
       "4330  4331      103    shorten        1293   \n",
       "4331  4332      243   discover        1294   \n",
       "4333  4334      198   decrease         210   \n",
       "4334  4335      190  suffocate         354   \n",
       "\n",
       "                                               response                start  \\\n",
       "4329  [6, 0, 0, 3, 4, 0, 1, 6, 5, 2, 3, 6, 0, 0, 1, ...  2021-08-12 22:53:52   \n",
       "4330  [5, 5, 5, 5, 5, 6, 4, 6, 6, 5, 4, 3, 4, 4, 4, ...  2021-08-12 23:06:49   \n",
       "4331  [3, 5, 4, 5, 4, 5, 4, 4, 5, 4, 5, 5, 4, 5, 5, ...  2021-08-12 23:37:43   \n",
       "4333  [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 5, 0, 4, 1, ...  2021-08-13 03:32:09   \n",
       "4334  [2, 0, 1, 3, 0, 0, 0, 3, 3, 3, 2, 0, 3, 4, 3, ...  2021-08-12 12:43:47   \n",
       "\n",
       "                      end                                                 RT  \\\n",
       "4329  2021-08-12 23:02:54  [4871, 7642, 3484, 6609, 7112, 5096, 9510, 492...   \n",
       "4330  2021-08-12 23:40:48  [667924, 14420, 20586, 4278, 2270, 6312, 9264,...   \n",
       "4331  2021-08-12 23:47:34  [1992, 1873, 1567, 3326, 2023, 3199, 1328, 270...   \n",
       "4333  2021-08-13 03:37:55  [1976, 4112, 2681, 2408, 2120, 7560, 8361, 344...   \n",
       "4334  2021-08-13 10:28:09  [10243, 6059, 10749, 7117, 21965, 5991, 5651, ...   \n",
       "\n",
       "                                            buttonpress  turkcode  \\\n",
       "4329  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   5192660   \n",
       "4330  [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   2285767   \n",
       "4331  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   1553234   \n",
       "4333  [1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, ...   8451568   \n",
       "4334  [1, 1, 3, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, ...   2647805   \n",
       "\n",
       "         subject_num gender  age education          occupation  results_id  \\\n",
       "4329  A1ZVJG3BKYHJWN      f   65        14  retailstorecashier        3776   \n",
       "4330   APG9EK6P41THO      m   48        16                 NaN        3777   \n",
       "4331    A4SQSL2ZCEU1      f   48         3                  15        3778   \n",
       "4333  A2LV5432PV1S39      m   34        16    DeputyCourtClerk        3780   \n",
       "4334   APZQ9ADUXTS7N      f   66        14                 NaN        3781   \n",
       "\n",
       "      catch_subject_id   catch_response  correctN badsubject  \n",
       "4329              1292  [0, 6, 0, 6, 6]         4          N  \n",
       "4330              1293  [0, 6, 0, 6, 6]         4          N  \n",
       "4331              1294  [4, 6, 0, 6, 6]         4          N  \n",
       "4333               210  [0, 6, 0, 6, 6]         4          N  \n",
       "4334               354  [0, 6, 0, 6, 6]         4          N  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "########calculate intersubject correlation and update res\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "res_dict = res.set_index('id').to_dict(orient='index')\n",
    "for k, v in res_dict.items():\n",
    "    response = v['response']\n",
    "    check = v['stim'] == avg_dict[v['stim_id']]['stim']\n",
    "    if check == False:\n",
    "        print ('something wrong!')\n",
    "    group_response = avg_dict[v['stim_id']]['avg_rating']\n",
    "    v['corr'] = round(pearsonr(response, group_response)[0],3) ###correlation b/w this vector and group average vector for word X.\n",
    "    v['corr_fisher'] = np.arctanh(v['corr'])\n",
    "#pearsonr(response, group_response)[0]\n",
    "\n",
    "### convert res_dict to df\n",
    "res_upd = pd.DataFrame.from_dict(res_dict, orient='index')\n",
    "\n",
    "\n",
    "### write res_upd to csv \n",
    "res_upd.to_csv(savepath + '/HITs_clean_with_correlations_0813.csv', index=False) ### clean HITs after dropping catch-failed HITs\n",
    "\n",
    "# min(res_upd['corr_fisher'].values.tolist())\n",
    "# res_upd2= res_upd.drop(columns=[\"RT\", \"buttonpress\",\"turkcode\",\"subject_num\", \"catch_subject_id\",\"occupation\"])\n",
    "# res_upd2.loc[res_upd['badsubject']=='Y', ].sort_values(by='corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f9b193df690>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### plot histogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "res_upd.hist(column='corr_fisher', cumulative=True, bins=150, ax=ax)\n",
    "#fig.savefig(savepath+'/subj_to_group_corr_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Part 2: find out bad words\n",
    "quesf = '/Users/songkim/GoogleDrive/Primary/Projects/VerbVector/AMT/html/experiments/ratings2/stimuli/questions.txt'\n",
    "ques = pd.read_csv(quesf, delimiter='\\t', header=None).iloc[:, :2].rename(columns={0:'fname', 1:'question'})\n",
    "q_dict = ques.to_dict(orient='index')\n",
    "\n",
    "#find only \"verb\" features\n",
    "new_q = ques.iloc[67:,]₩ㅁ\n",
    "caused = ques.loc[ques['fname']=='Caused',]\n",
    "\n",
    "verb_ques = pd.concat([caused, new_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_dict[46]['fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export data (for each verb, one response for each feature)\n",
    "\n",
    "res_sub = res_upd[[\"stim_id\", \"stim\", \"subject_id\", \"response\",\"correctN\",\"corr_fisher\"]]\n",
    "\n",
    "new_column= list(range(response_n)) #[0,1,2,...71]\n",
    "res_sub[new_column] = pd.DataFrame(res_sub.response.tolist(), index= res_sub.index)\n",
    "res_sub = res_sub[[\"stim_id\", \"stim\", \"subject_id\", \"correctN\", \"corr_fisher\", 46, 67, 68, 69, 70, 71]]\n",
    "\n",
    "d = dict()\n",
    "for i in [46,67,68,69,70,71]:\n",
    "    d[i] = q_dict[i]['fname']\n",
    "\n",
    "res_sub = res_sub.rename(columns=d)\n",
    "res_sub.head()\n",
    "\n",
    "##export res_sub\n",
    "savepath = '/Users/songkim/GoogleDrive/Primary/Projects/VerbVector/AMT/html/experiments/ratings2/results'\n",
    "res_sub.to_csv(savepath+'/clean_5features_individual.csv', index=False)\n",
    "\n",
    "#df2[['team1','team2']] = pd.DataFrame(df2.teams.tolist(), index= df2.index)\n",
    "#to_add = pd.DataFrame(res_sub.response.tolist()).iloc[:, [46,67,68,69,70,71]]\n",
    "#pd.DataFrame(res_sub.response.tolist())\n",
    "#df2[['team1','team2']] = pd.DataFrame(df2.teams.tolist(), index= df2.index)\n",
    "#df_responses = pd.DataFrame(df.response.tolist(), columns=column).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########PART3: integrate SD dataframe with verblist\n",
    "sdpath = '/Users/songkim/GoogleDrive/Primary/Projects/VerbVector/AMT/html/experiments/ratings2/results/SD_by_word_and_feature.csv'\n",
    "listpath = '/Users/songkim/GoogleDrive/Primary/Projects/VerbVector/Verblists/List320.csv'\n",
    "\n",
    "df_sd = pd.read_csv(sdpath, index_col=0)\n",
    "df_list = pd.read_csv(listpath)\n",
    "df_list = df_list.loc[df_list['in']==1]\n",
    "\n",
    "###merge of verblist \n",
    "df_sd_upd = pd.merge(left=df_sd, right=df_list, left_on= 'word', right_on='Lemma')\n",
    "\n",
    "#### clean up merged df\n",
    "df_sd_upd.drop(columns=['Lemma', 'badverb', 'GrandIndex', 'in', 'whyexcluded', \n",
    "                        'abs_marginality', 'rel_marginality', 'SynClassLitrt', 'SynClassSK', 'good'], inplace=True)\n",
    "\n",
    "\n",
    "#### add <mean (subject-to-group) correlation to df_sd_upd ##### \n",
    "corr_raw = pd.read_csv(savepath + '/HITs_clean_with_correlations.csv')\n",
    "corr_raw = corr_raw[[\"stim_id\", \"stim\", \"subject_id\", \"corr_fisher\"]]\n",
    "corr_raw['corr_fisher'] = corr_raw['corr_fisher'].round(decimals=3)\n",
    "corr_dict = {}\n",
    "for i in range(1,321):\n",
    "    df_sel = corr_raw.loc[corr_raw['stim_id']==i]\n",
    "    stim_id = df_sel.iloc[0]['stim_id']\n",
    "    word = df_sel.iloc[0]['stim']\n",
    "    corr_list = df_sel['corr_fisher'].values.tolist()\n",
    "    corr_list.sort(reverse=True)\n",
    "    corr_list = [round(c,2) for c in corr_list]\n",
    "    mean_corr = round(df_sel['corr_fisher'].mean(), 2)\n",
    "    d_add = {'stim_id': stim_id, 'word': word, 'corr_list':corr_list, 'mean_fcorr':mean_corr}\n",
    "    corr_dict[i] = d_add\n",
    "    \n",
    "corr_df = pd.DataFrame.from_dict(corr_dict, orient='index')\n",
    "\n",
    "\n",
    "df_sd_out = pd.merge(left=df_sd_upd, right=corr_df, on='word')\n",
    "df_sd_out = rearrange_col(df_sd_out, 'mean_fcorr', 'meanSD')\n",
    "df_sd_out = rearrange_col(df_sd_out, 'corr_list', 'mean_fcorr')\n",
    "######\n",
    "\n",
    "### write to csv\n",
    "savepath = '/Users/songkim/GoogleDrive/Primary/Projects/VerbVector/AMT/html/experiments/ratings2/results'\n",
    "df_sd_out.to_csv(savepath + '/list320_with_sd_correlation.csv', index=False)\n",
    "\n",
    "\n",
    "## plotting\n",
    "#df_sd_out.plot(x=\"stim_id\", y=[\"mean_fcorr\"], kind=\"hist\")\n",
    "df_sd_out.plot(y=[\"mean_fcorr\"], kind=\"hist\")\n",
    "df_sd_out.plot(y=[\"meanSD\"], kind=\"hist\")\n",
    "\n",
    "df_sd_out.plot(x=\"SynClass\", y=\"mean_fcorr\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd_upd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd_upd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "df = corr_raw.loc[corr_raw['stim_id']==i]\n",
    "corr_list = df['corr_fisher'].values.tolist()\n",
    "corr_list = [round(c,2) for c in corr_list]\n",
    "mean_corr = round(df['corr_fisher'].mean(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_raw.loc[corr_raw['stim_id']==1]['corr_fisher'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_raw.loc[corr_raw['stim_id']==1]['corr_fisher'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd_upd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add \"mean (subject-to-group) correlation\"\n",
    "df_sd_upd['meanCorrelation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd_upd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd_upd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sd_upd['word'].equals(df_sd_upd['Lemma'])\n",
    "set(df_sd_upd['in'].values.tolist())\n",
    "#df['Score A'].equals(df['Score B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_1 = [1, 1, 1, 1]\n",
    "# list_2 = [-1, -1, -1, -1]\n",
    "# list_3 = [1, 3, 5, 7]\n",
    "# list_4 = [0,0,0,100]\n",
    "# dfx=pd.DataFrame({\"list_1\":list_1,\"list_2\":list_2,\"list_3\":list_3,\"list_4\":list_4})\n",
    "# dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1= '0_6_0_6_6'\n",
    "# t1.split('_')\n",
    "\n",
    "# testlist = ['5', '7', '3', '0', '6', '0', '3', '1', '0']\n",
    "# ['0' if t=='7' else t for t in testlist]\n",
    "#new_prices = [round(price - (price * 10 / 100), 2) if price > 50 else price for price in prices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### spread responses into separate columns\n",
    "# df_test = res[[\"id\", \"stim_id\", \"response\"]]\n",
    "\n",
    "#print ('before spreading:', res.shape)\n",
    "\n",
    "# response_n = len(res.iloc[0][\"response\"])\n",
    "# column = []\n",
    "# for i in range(1, response_n+1):\n",
    "#     column.append('q'+str(i))  ##### column = ['q1', 'q2', ... 'q72']\n",
    "\n",
    "# res[column] = pd.DataFrame(res.response.tolist(), index=res.index)\n",
    "\n",
    "# print ('after spreading:', res.shape)\n",
    "\n",
    "#res.tail()\n",
    "\n",
    "#df2[['team1','team2']] = pd.DataFrame(df2.teams.tolist(), index= df2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in range(len(res_upd.iloc[0]['response'])):\n",
    "#     print (r, res_upd.iloc[0]['response'][r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.arctanh(0.767)\n",
    "\n",
    "# from scipy.stats import zprob\n",
    "# def z_transform(r, n):\n",
    "#     z = np.log((1 + r) / (1 - r)) * (np.sqrt(n - 3) / 2)\n",
    "#     p = zprob(-z)\n",
    "#     return p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
