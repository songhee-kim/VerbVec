{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "### starts from raw AMT ratings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "%pprint off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['backup0_1_550', 'backup_210813', 'backup_210831', 'backup1_550-1050', 'backup3_0628', 'backup2_0610']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/songheekim/GoogleDrive/Primary/Projects/VerbVector/AMT/html/experiments/ratings2/results/'\n",
    "backups = next(os.walk(path))[1]\n",
    "backups = [b for b in backups if b.startswith('backup')]\n",
    "backups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_col(dataframe, col_to_move, reference_col, right=True):\n",
    "    col_list = dataframe.columns.values.tolist()\n",
    "    col_list2 = [x for x in col_list if x != col_to_move]\n",
    "    reference_idx = col_list2.index(reference_col)\n",
    "    if right==True:\n",
    "        col_list3 = []\n",
    "        for y in col_list2:\n",
    "            col_list3.append(y)\n",
    "            if y == reference_col:\n",
    "                col_list3.append(col_to_move)\n",
    "        return dataframe[col_list3]\n",
    "    else:\n",
    "        col_list3 = []\n",
    "        for y in col_list2:\n",
    "            col_list3.append(y)\n",
    "            if y == reference_col:\n",
    "                col_list3.insert(-2, col_to_move)\n",
    "        return  dataframe[col_list3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_res_catch_subj(backupfolder):\n",
    "    \n",
    "    path = '/Users/songheekim/GoogleDrive/Primary/Projects/VerbVector/AMT/html/experiments/ratings2/results/'\n",
    "#     stimr = pd.read_csv(path+backupfolder+'/'+'wro1_stimuli.txt', delimiter=\"\\t\")\n",
    "#     stim = stimr[stimr['id'].notna()][[\"id\", \"stim\"]].reset_index(drop=True).astype({\"id\": int})\n",
    "#     stim['stim'] = stim['stim'].str[:-1]\n",
    "\n",
    "    catchr = pd.read_csv(path+backupfolder+'/'+'wro1_catchresults.txt',delimiter=\"\\t\")\n",
    "    catch = catchr.rename(columns={\"response\": \"catch_response\", \"subject_id\":\"catch_subject_id\"})\n",
    "\n",
    "    resr = pd.read_csv(path+backupfolder+'/'+'wro1_results.txt', delimiter=\"\\t\")\n",
    "    res = resr.drop(columns=['stimtype_id','sense'])\n",
    "\n",
    "    subj_raw = pd.read_csv(path+backupfolder+'/'+'wro1_subjects.txt',delimiter=\"\\t\")\n",
    "    subj = subj_raw.rename(columns={\"id\": \"subject_id\"})\n",
    "\n",
    "    return (res, catch, subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backup selected: backup_210831\n",
      "['.DS_Store', 'wro1_stimuli.txt', 'wro1_subjects.txt', 'wro1_catchresults.txt', 'wro1_results.txt', 'wro1_questions.txt']\n",
      "catch trial: 1518\n",
      "This data contains ratings collected from 2021-08-24 12:37:49 to 2021-08-28 13:11:00\n",
      "subject N: 874\n",
      "# of questions: 72\n",
      "# of catch HITs: 1518\n",
      "# of HITs:      1518\n",
      "# of subjects:  874\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "#### basic check on each dataset ##### \n",
    "b=backups[2]\n",
    "\n",
    "print('backup selected:', b)\n",
    "print(os.listdir(path+'/'+b))\n",
    "\n",
    "stimr = pd.read_csv(path+b+'/'+'wro1_stimuli.txt', delimiter=\"\\t\") # r means 'raw'\n",
    "stim = stimr[stimr['id'].notna()][[\"id\", \"stim\"]].reset_index(drop=True).astype({\"id\": int})\n",
    "stim['stim'] = stim['stim'].str[:-1]\n",
    "\n",
    "ques = pd.read_csv(path+b+'/'+'wro1_questions.txt', delimiter=\"\\t\")\n",
    "catchr = pd.read_csv(path+b+'/'+'wro1_catchresults.txt',delimiter=\"\\t\")\n",
    "catch = catchr.rename(columns={\"response\": \"catch_response\", \"subject_id\":\"catch_subject_id\"})\n",
    "print (\"catch trial:\", catch.shape[0])\n",
    "\n",
    "resr = pd.read_csv(path+b+'/'+'wro1_results.txt', delimiter=\"\\t\")\n",
    "res = resr.drop(columns=['stimtype_id','sense'])\n",
    "#print (\"main trial:\", res.shape[0])\n",
    "starttime = res.loc[res['id']==1, \"start\"].values[0]\n",
    "endtime = res.loc[res['id']==res.shape[0], \"end\"].values[0]\n",
    "print('This data contains ratings collected from', starttime, 'to', endtime)\n",
    "\n",
    "subj_raw = pd.read_csv(path+b+'/'+'wro1_subjects.txt',delimiter=\"\\t\")\n",
    "subj = subj_raw.rename(columns={\"id\": \"subject_id\"})\n",
    "print('subject N:', subj.shape[0])\n",
    "\n",
    "print('# of questions:', ques.shape[0])\n",
    "print('# of catch HITs:', catch.shape[0])\n",
    "print('# of HITs:     ', res.shape[0])\n",
    "print('# of subjects: ', subj.shape[0])\n",
    "\n",
    "check1 = catch.shape[0] == res.shape[0]\n",
    "check2 = res.shape[0] >= subj.shape[0] \n",
    "check3 = res['subject_id'].equals(other=catch['catch_subject_id'])\n",
    "\n",
    "if check1==0:\n",
    "    print ('# of catch trials != # of trials')\n",
    "elif check2==0:\n",
    "    print ('# of subjects are more than # of HITs')\n",
    "elif check3==0:\n",
    "    print('subject_id are not the same in trials and catchtrials')\n",
    "\n",
    "print ('=============================================') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######catch trial info\n",
    "catch1 = 'being an animal living on the surface of sun'\n",
    "catch2 = 'being something about which you are supposed to answer questions in this assignment'\n",
    "catch3 = 'being an object that is smaller than a shoe box and larger than a mountain'\n",
    "catch4 = 'being something you have thought about within the last couple minutes'\n",
    "catch5 = 'being used to check whether you are carefully reading the questions'\n",
    "catch_answers = ['0/7','6','0','6','6']\n",
    "\n",
    "# def count_correct_answers(list1):\n",
    "#     catch_answers = ['0/7','6','0','6','6']\n",
    "#     if len(list1) != len(catch_answers):\n",
    "#         print ('responses have different lengths!')\n",
    "#         return\n",
    "#     correct_answer = 0\n",
    "#     if list1[0] in catch_answers[0].split('/'):\n",
    "#         correct_answer += 1\n",
    "#     for i in range(1,len(list1)):\n",
    "#         iscorrect = list1[i]==catch_answers[i]\n",
    "#         correct_answer += iscorrect        \n",
    "#     return correct_answer\n",
    "\n",
    "def count_incorrect_answers(list1):\n",
    "    catch_answers = ['0/7','6','0','6','6']\n",
    "    if len(list1) != len(catch_answers):\n",
    "        print ('responses have different lengths!')\n",
    "        return\n",
    "    correct_answer = 0\n",
    "    if list1[0] in catch_answers[0].split('/'):\n",
    "        correct_answer += 1\n",
    "    for i in range(1,len(list1)):\n",
    "        iscorrect = list1[i]==catch_answers[i]\n",
    "        correct_answer += iscorrect        \n",
    "    return (5-correct_answer)\n",
    "\n",
    "count_incorrect_answers(['1', '6', '0', '6', '6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tables(backupfolder): \n",
    "    '''function that merges results table, catch table, and subject table \n",
    "       backupfolder = the rating folder of interest'''\n",
    "    [res, catch, subj] = return_res_catch_subj(backupfolder)\n",
    "    \n",
    "    res_all = pd.merge(left=res, right=subj, on='subject_id')\n",
    "    res_all = res_all.sort_values(by=['id'])\n",
    "    print('result df:', res.shape)\n",
    "    print('subject df:', subj.shape)\n",
    "    print('df returned:', res_all.shape)\n",
    "    \n",
    "    catch = catch.drop(columns='id') \n",
    "    res_all = pd.merge(left=res_all, right=catch, left_on=\"id\", right_on=\"results_id\")\n",
    "    \n",
    "    #print(res_all.shape)\n",
    "    #print(catch.shape)\n",
    "    print ('=========================================================')\n",
    "    \n",
    "    return res_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result df: (1518, 9)\n",
      "subject df: (874, 6)\n",
      "df returned: (1518, 14)\n",
      "=========================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stim_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>response</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>rt</th>\n",
       "      <th>buttonpress</th>\n",
       "      <th>turkcode</th>\n",
       "      <th>subject_num</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>occupation</th>\n",
       "      <th>results_id</th>\n",
       "      <th>catch_subject_id</th>\n",
       "      <th>catch_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>0_0_0_0_0_0_0_0_0_0_0_0_2_0_0_0_0_0_0_0_0_0_3_...</td>\n",
       "      <td>2021-08-24 12:37:49</td>\n",
       "      <td>2021-08-24 12:43:52</td>\n",
       "      <td>5841_1584_1808_2144_2008_2680_3416_11448_11423...</td>\n",
       "      <td>2_1_1_1_1_1_1_1_3_1_1_1_1_1_1_1_1_1_1_1_1_1_1_...</td>\n",
       "      <td>7467737</td>\n",
       "      <td>ADJ9I7ZBFYFH7</td>\n",
       "      <td>m</td>\n",
       "      <td>32</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Security at a warehouse</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0_6_0_6_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>0_0_0_1_3_0_0_0_0_0_1_2_0_0_0_1_3_0_0_0_0_0_0_...</td>\n",
       "      <td>2021-08-24 12:36:28</td>\n",
       "      <td>2021-08-24 12:49:54</td>\n",
       "      <td>5114_2594_2164_8210_26407_2706_9729_11037_3966...</td>\n",
       "      <td>1_1_1_2_1_1_4_1_1_1_2_2_1_2_1_1_5_1_1_1_1_1_1_...</td>\n",
       "      <td>5481024</td>\n",
       "      <td>A3NKZMF7M4X0ZP</td>\n",
       "      <td>m</td>\n",
       "      <td>27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0_6_0_6_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3_0_0_0_1_0_1_6_6_6_3_2_1_6_0_0_0_0_0_0_0_3_0_...</td>\n",
       "      <td>2021-08-24 12:47:34</td>\n",
       "      <td>2021-08-24 12:52:58</td>\n",
       "      <td>4728_1777_1777_1864_11745_2536_4121_4793_4040_...</td>\n",
       "      <td>2_1_1_1_2_1_1_2_1_3_1_1_3_1_1_1_2_1_1_1_1_1_1_...</td>\n",
       "      <td>3663884</td>\n",
       "      <td>A2OG7XGWOX5ZEF</td>\n",
       "      <td>m</td>\n",
       "      <td>33</td>\n",
       "      <td>14.0</td>\n",
       "      <td>I work at a large retail store moving items an...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0_6_0_6_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>5_0_0_0_0_0_0_4_6_4_1_0_0_6_0_0_0_0_0_0_0_0_0_...</td>\n",
       "      <td>2021-08-24 12:49:04</td>\n",
       "      <td>2021-08-24 13:00:17</td>\n",
       "      <td>13362_2288_3391_3672_4813_3144_5584_6477_7000_...</td>\n",
       "      <td>2_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_2_1_1_...</td>\n",
       "      <td>1561528</td>\n",
       "      <td>A170R0WAZC31WC</td>\n",
       "      <td>f</td>\n",
       "      <td>51</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Variable data tech for print on demand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0_6_0_6_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>3_3_0_2_0_0_1_3_6_1_1_0_2_4_1_2_1_0_0_0_0_3_2_...</td>\n",
       "      <td>2021-08-24 13:23:42</td>\n",
       "      <td>2021-08-24 13:31:44</td>\n",
       "      <td>7343_3488_3920_7568_2992_3808_4968_6368_3896_2...</td>\n",
       "      <td>2_1_1_1_1_1_1_2_1_1_1_1_1_1_1_1_2_1_2_1_1_2_1_...</td>\n",
       "      <td>1183680</td>\n",
       "      <td>AAXX5LDVJ32F8</td>\n",
       "      <td>m</td>\n",
       "      <td>49</td>\n",
       "      <td>12.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0_6_0_6_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>1514</td>\n",
       "      <td>254</td>\n",
       "      <td>872</td>\n",
       "      <td>5_3_1_2_4_4_3_1_1_2_2_1_0_2_6_3_2_4_3_1_1_1_3_...</td>\n",
       "      <td>2021-08-28 09:38:19</td>\n",
       "      <td>2021-08-28 09:48:43</td>\n",
       "      <td>3744_2720_2944_5064_5416_10400_4312_4416_3016_...</td>\n",
       "      <td>1_1_1_1_1_1_1_2_1_1_1_1_1_1_1_1_3_2_1_1_1_1_1_...</td>\n",
       "      <td>7910923</td>\n",
       "      <td>ALTSDQ7JAWE7E</td>\n",
       "      <td>f</td>\n",
       "      <td>39</td>\n",
       "      <td>16.0</td>\n",
       "      <td>AR Specialist for my full time job and office ...</td>\n",
       "      <td>1514</td>\n",
       "      <td>872</td>\n",
       "      <td>0_6_0_6_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>1515</td>\n",
       "      <td>45</td>\n",
       "      <td>873</td>\n",
       "      <td>6_3_6_3_2_6_2_3_3_6_3_3_6_6_3_3_2_6_3_2_6_2_3_...</td>\n",
       "      <td>2021-08-28 09:44:10</td>\n",
       "      <td>2021-08-28 10:01:13</td>\n",
       "      <td>5328_3789_2640_3636_15144_3160_2187_3971_3087_...</td>\n",
       "      <td>1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_...</td>\n",
       "      <td>6194369</td>\n",
       "      <td>A1N35VV9QURKHX</td>\n",
       "      <td>f</td>\n",
       "      <td>45</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Information  Data Entry</td>\n",
       "      <td>1515</td>\n",
       "      <td>873</td>\n",
       "      <td>7_6_0_6_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>1516</td>\n",
       "      <td>35</td>\n",
       "      <td>645</td>\n",
       "      <td>1_0_1_0_0_0_0_0_5_0_1_0_5_3_0_0_1_1_0_0_1_3_5_...</td>\n",
       "      <td>2021-08-28 10:18:07</td>\n",
       "      <td>2021-08-28 10:32:48</td>\n",
       "      <td>6088_3116_5168_33664_3972_4848_3268_3456_12468...</td>\n",
       "      <td>1_1_1_1_1_2_2_1_1_1_1_1_1_2_1_1_2_1_1_1_2_1_1_...</td>\n",
       "      <td>6822510</td>\n",
       "      <td>A3O0ZQMDKOKAMR</td>\n",
       "      <td>f</td>\n",
       "      <td>44</td>\n",
       "      <td>12.0</td>\n",
       "      <td>I am a fulltime Decorator for a retail grocery...</td>\n",
       "      <td>1516</td>\n",
       "      <td>645</td>\n",
       "      <td>0_6_0_6_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>1517</td>\n",
       "      <td>29</td>\n",
       "      <td>577</td>\n",
       "      <td>5_0_0_0_0_0_0_1_6_2_3_0_2_5_6_6_1_5_0_0_1_1_1_...</td>\n",
       "      <td>2021-08-28 10:37:50</td>\n",
       "      <td>2021-08-28 10:53:09</td>\n",
       "      <td>4344_2234_2390_9221_20266_128198_21287_7657_96...</td>\n",
       "      <td>1_1_1_1_1_1_1_1_1_1_1_1_2_1_1_1_2_1_1_1_1_1_1_...</td>\n",
       "      <td>3616355</td>\n",
       "      <td>A49A0FF6ZXYDU</td>\n",
       "      <td>f</td>\n",
       "      <td>53</td>\n",
       "      <td>16.0</td>\n",
       "      <td>library staff</td>\n",
       "      <td>1517</td>\n",
       "      <td>577</td>\n",
       "      <td>0_6_0_6_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1518</td>\n",
       "      <td>242</td>\n",
       "      <td>874</td>\n",
       "      <td>0_0_0_2_0_0_0_0_1_1_2_0_1_3_0_0_0_0_0_0_0_3_0_...</td>\n",
       "      <td>2021-08-28 13:04:57</td>\n",
       "      <td>2021-08-28 13:11:00</td>\n",
       "      <td>3307_4664_2538_4412_4110_8903_5728_2330_4008_3...</td>\n",
       "      <td>1_1_1_3_1_1_1_1_1_1_2_1_1_1_1_1_1_1_1_1_1_1_1_...</td>\n",
       "      <td>8684799</td>\n",
       "      <td>A3S2R1NK6HZ9KP</td>\n",
       "      <td>f</td>\n",
       "      <td>36</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>1518</td>\n",
       "      <td>874</td>\n",
       "      <td>0_6_0_0_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1518 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  stim_id  subject_id  \\\n",
       "0        1      294           1   \n",
       "1        2      208           2   \n",
       "2        3       40           3   \n",
       "3        4       57           4   \n",
       "4        5       22           5   \n",
       "...    ...      ...         ...   \n",
       "1513  1514      254         872   \n",
       "1514  1515       45         873   \n",
       "1515  1516       35         645   \n",
       "1516  1517       29         577   \n",
       "1517  1518      242         874   \n",
       "\n",
       "                                               response                start  \\\n",
       "0     0_0_0_0_0_0_0_0_0_0_0_0_2_0_0_0_0_0_0_0_0_0_3_...  2021-08-24 12:37:49   \n",
       "1     0_0_0_1_3_0_0_0_0_0_1_2_0_0_0_1_3_0_0_0_0_0_0_...  2021-08-24 12:36:28   \n",
       "2     3_0_0_0_1_0_1_6_6_6_3_2_1_6_0_0_0_0_0_0_0_3_0_...  2021-08-24 12:47:34   \n",
       "3     5_0_0_0_0_0_0_4_6_4_1_0_0_6_0_0_0_0_0_0_0_0_0_...  2021-08-24 12:49:04   \n",
       "4     3_3_0_2_0_0_1_3_6_1_1_0_2_4_1_2_1_0_0_0_0_3_2_...  2021-08-24 13:23:42   \n",
       "...                                                 ...                  ...   \n",
       "1513  5_3_1_2_4_4_3_1_1_2_2_1_0_2_6_3_2_4_3_1_1_1_3_...  2021-08-28 09:38:19   \n",
       "1514  6_3_6_3_2_6_2_3_3_6_3_3_6_6_3_3_2_6_3_2_6_2_3_...  2021-08-28 09:44:10   \n",
       "1515  1_0_1_0_0_0_0_0_5_0_1_0_5_3_0_0_1_1_0_0_1_3_5_...  2021-08-28 10:18:07   \n",
       "1516  5_0_0_0_0_0_0_1_6_2_3_0_2_5_6_6_1_5_0_0_1_1_1_...  2021-08-28 10:37:50   \n",
       "1517  0_0_0_2_0_0_0_0_1_1_2_0_1_3_0_0_0_0_0_0_0_3_0_...  2021-08-28 13:04:57   \n",
       "\n",
       "                      end                                                 rt  \\\n",
       "0     2021-08-24 12:43:52  5841_1584_1808_2144_2008_2680_3416_11448_11423...   \n",
       "1     2021-08-24 12:49:54  5114_2594_2164_8210_26407_2706_9729_11037_3966...   \n",
       "2     2021-08-24 12:52:58  4728_1777_1777_1864_11745_2536_4121_4793_4040_...   \n",
       "3     2021-08-24 13:00:17  13362_2288_3391_3672_4813_3144_5584_6477_7000_...   \n",
       "4     2021-08-24 13:31:44  7343_3488_3920_7568_2992_3808_4968_6368_3896_2...   \n",
       "...                   ...                                                ...   \n",
       "1513  2021-08-28 09:48:43  3744_2720_2944_5064_5416_10400_4312_4416_3016_...   \n",
       "1514  2021-08-28 10:01:13  5328_3789_2640_3636_15144_3160_2187_3971_3087_...   \n",
       "1515  2021-08-28 10:32:48  6088_3116_5168_33664_3972_4848_3268_3456_12468...   \n",
       "1516  2021-08-28 10:53:09  4344_2234_2390_9221_20266_128198_21287_7657_96...   \n",
       "1517  2021-08-28 13:11:00  3307_4664_2538_4412_4110_8903_5728_2330_4008_3...   \n",
       "\n",
       "                                            buttonpress  turkcode  \\\n",
       "0     2_1_1_1_1_1_1_1_3_1_1_1_1_1_1_1_1_1_1_1_1_1_1_...   7467737   \n",
       "1     1_1_1_2_1_1_4_1_1_1_2_2_1_2_1_1_5_1_1_1_1_1_1_...   5481024   \n",
       "2     2_1_1_1_2_1_1_2_1_3_1_1_3_1_1_1_2_1_1_1_1_1_1_...   3663884   \n",
       "3     2_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_2_1_1_...   1561528   \n",
       "4     2_1_1_1_1_1_1_2_1_1_1_1_1_1_1_1_2_1_2_1_1_2_1_...   1183680   \n",
       "...                                                 ...       ...   \n",
       "1513  1_1_1_1_1_1_1_2_1_1_1_1_1_1_1_1_3_2_1_1_1_1_1_...   7910923   \n",
       "1514  1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_...   6194369   \n",
       "1515  1_1_1_1_1_2_2_1_1_1_1_1_1_2_1_1_2_1_1_1_2_1_1_...   6822510   \n",
       "1516  1_1_1_1_1_1_1_1_1_1_1_1_2_1_1_1_2_1_1_1_1_1_1_...   3616355   \n",
       "1517  1_1_1_3_1_1_1_1_1_1_2_1_1_1_1_1_1_1_1_1_1_1_1_...   8684799   \n",
       "\n",
       "         subject_num gender  age  education  \\\n",
       "0      ADJ9I7ZBFYFH7      m   32       13.0   \n",
       "1     A3NKZMF7M4X0ZP      m   27       16.0   \n",
       "2     A2OG7XGWOX5ZEF      m   33       14.0   \n",
       "3     A170R0WAZC31WC      f   51       15.0   \n",
       "4      AAXX5LDVJ32F8      m   49       12.0   \n",
       "...              ...    ...  ...        ...   \n",
       "1513   ALTSDQ7JAWE7E      f   39       16.0   \n",
       "1514  A1N35VV9QURKHX      f   45       14.0   \n",
       "1515  A3O0ZQMDKOKAMR      f   44       12.0   \n",
       "1516   A49A0FF6ZXYDU      f   53       16.0   \n",
       "1517  A3S2R1NK6HZ9KP      f   36       16.0   \n",
       "\n",
       "                                             occupation  results_id  \\\n",
       "0                              Security at a warehouse            1   \n",
       "1                                                   NaN           2   \n",
       "2     I work at a large retail store moving items an...           3   \n",
       "3               Variable data tech for print on demand            4   \n",
       "4                                            unemployed           5   \n",
       "...                                                 ...         ...   \n",
       "1513  AR Specialist for my full time job and office ...        1514   \n",
       "1514                           Information  Data Entry         1515   \n",
       "1515  I am a fulltime Decorator for a retail grocery...        1516   \n",
       "1516                                      library staff        1517   \n",
       "1517                                       Data Analyst        1518   \n",
       "\n",
       "      catch_subject_id catch_response  \n",
       "0                    1      0_6_0_6_6  \n",
       "1                    2      0_6_0_6_6  \n",
       "2                    3      0_6_0_6_6  \n",
       "3                    4      0_6_0_6_6  \n",
       "4                    5      0_6_0_6_6  \n",
       "...                ...            ...  \n",
       "1513               872      0_6_0_6_6  \n",
       "1514               873      7_6_0_6_6  \n",
       "1515               645      0_6_0_6_6  \n",
       "1516               577      0_6_0_6_6  \n",
       "1517               874      0_6_0_0_6  \n",
       "\n",
       "[1518 rows x 17 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result df: (1518, 9)\n",
      "subject df: (874, 6)\n",
      "df returned: (1518, 14)\n",
      "=========================================================\n",
      "# of bad subject: 11 out of 1518\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stim_id</th>\n",
       "      <th>stim</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>response</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>RT</th>\n",
       "      <th>buttonpress</th>\n",
       "      <th>turkcode</th>\n",
       "      <th>subject_num</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>occupation</th>\n",
       "      <th>results_id</th>\n",
       "      <th>catch_subject_id</th>\n",
       "      <th>catch_response</th>\n",
       "      <th>incorrectN</th>\n",
       "      <th>badsubject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>imply</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, ...</td>\n",
       "      <td>2021-08-24 12:37:49</td>\n",
       "      <td>2021-08-24 12:43:52</td>\n",
       "      <td>[5841, 1584, 1808, 2144, 2008, 2680, 3416, 114...</td>\n",
       "      <td>[2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>7467737</td>\n",
       "      <td>ADJ9I7ZBFYFH7</td>\n",
       "      <td>m</td>\n",
       "      <td>32</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Security at a warehouse</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>208</td>\n",
       "      <td>thaw</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, ...</td>\n",
       "      <td>2021-08-24 12:36:28</td>\n",
       "      <td>2021-08-24 12:49:54</td>\n",
       "      <td>[5114, 2594, 2164, 8210, 26407, 2706, 9729, 11...</td>\n",
       "      <td>[1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 2, 2, 1, 2, 1, ...</td>\n",
       "      <td>5481024</td>\n",
       "      <td>A3NKZMF7M4X0ZP</td>\n",
       "      <td>m</td>\n",
       "      <td>27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>wriggle</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 0, 0, 0, 1, 0, 1, 6, 6, 6, 3, 2, 1, 6, 0, ...</td>\n",
       "      <td>2021-08-24 12:47:34</td>\n",
       "      <td>2021-08-24 12:52:58</td>\n",
       "      <td>[4728, 1777, 1777, 1864, 11745, 2536, 4121, 47...</td>\n",
       "      <td>[2, 1, 1, 1, 2, 1, 1, 2, 1, 3, 1, 1, 3, 1, 1, ...</td>\n",
       "      <td>3663884</td>\n",
       "      <td>A2OG7XGWOX5ZEF</td>\n",
       "      <td>m</td>\n",
       "      <td>33</td>\n",
       "      <td>14.0</td>\n",
       "      <td>I work at a large retail store moving items an...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>arrive</td>\n",
       "      <td>4</td>\n",
       "      <td>[5, 0, 0, 0, 0, 0, 0, 4, 6, 4, 1, 0, 0, 6, 0, ...</td>\n",
       "      <td>2021-08-24 12:49:04</td>\n",
       "      <td>2021-08-24 13:00:17</td>\n",
       "      <td>[13362, 2288, 3391, 3672, 4813, 3144, 5584, 64...</td>\n",
       "      <td>[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1561528</td>\n",
       "      <td>A170R0WAZC31WC</td>\n",
       "      <td>f</td>\n",
       "      <td>51</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Variable data tech for print on demand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>cringe</td>\n",
       "      <td>5</td>\n",
       "      <td>[3, 3, 0, 2, 0, 0, 1, 3, 6, 1, 1, 0, 2, 4, 1, ...</td>\n",
       "      <td>2021-08-24 13:23:42</td>\n",
       "      <td>2021-08-24 13:31:44</td>\n",
       "      <td>[7343, 3488, 3920, 7568, 2992, 3808, 4968, 636...</td>\n",
       "      <td>[2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1183680</td>\n",
       "      <td>AAXX5LDVJ32F8</td>\n",
       "      <td>m</td>\n",
       "      <td>49</td>\n",
       "      <td>12.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1514</td>\n",
       "      <td>254</td>\n",
       "      <td>activate</td>\n",
       "      <td>872</td>\n",
       "      <td>[5, 3, 1, 2, 4, 4, 3, 1, 1, 2, 2, 1, 0, 2, 6, ...</td>\n",
       "      <td>2021-08-28 09:38:19</td>\n",
       "      <td>2021-08-28 09:48:43</td>\n",
       "      <td>[3744, 2720, 2944, 5064, 5416, 10400, 4312, 44...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>7910923</td>\n",
       "      <td>ALTSDQ7JAWE7E</td>\n",
       "      <td>f</td>\n",
       "      <td>39</td>\n",
       "      <td>16.0</td>\n",
       "      <td>AR Specialist for my full time job and office ...</td>\n",
       "      <td>1514</td>\n",
       "      <td>872</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1515</td>\n",
       "      <td>45</td>\n",
       "      <td>start</td>\n",
       "      <td>873</td>\n",
       "      <td>[6, 3, 6, 3, 2, 6, 2, 3, 3, 6, 3, 3, 6, 6, 3, ...</td>\n",
       "      <td>2021-08-28 09:44:10</td>\n",
       "      <td>2021-08-28 10:01:13</td>\n",
       "      <td>[5328, 3789, 2640, 3636, 15144, 3160, 2187, 39...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>6194369</td>\n",
       "      <td>A1N35VV9QURKHX</td>\n",
       "      <td>f</td>\n",
       "      <td>45</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Information  Data Entry</td>\n",
       "      <td>1515</td>\n",
       "      <td>873</td>\n",
       "      <td>[7, 6, 0, 6, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>1516</td>\n",
       "      <td>35</td>\n",
       "      <td>wail</td>\n",
       "      <td>645</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 5, 0, 1, 0, 5, 3, 0, ...</td>\n",
       "      <td>2021-08-28 10:18:07</td>\n",
       "      <td>2021-08-28 10:32:48</td>\n",
       "      <td>[6088, 3116, 5168, 33664, 3972, 4848, 3268, 34...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, ...</td>\n",
       "      <td>6822510</td>\n",
       "      <td>A3O0ZQMDKOKAMR</td>\n",
       "      <td>f</td>\n",
       "      <td>44</td>\n",
       "      <td>12.0</td>\n",
       "      <td>I am a fulltime Decorator for a retail grocery...</td>\n",
       "      <td>1516</td>\n",
       "      <td>645</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>1517</td>\n",
       "      <td>29</td>\n",
       "      <td>bathe</td>\n",
       "      <td>577</td>\n",
       "      <td>[5, 0, 0, 0, 0, 0, 0, 1, 6, 2, 3, 0, 2, 5, 6, ...</td>\n",
       "      <td>2021-08-28 10:37:50</td>\n",
       "      <td>2021-08-28 10:53:09</td>\n",
       "      <td>[4344, 2234, 2390, 9221, 20266, 128198, 21287,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, ...</td>\n",
       "      <td>3616355</td>\n",
       "      <td>A49A0FF6ZXYDU</td>\n",
       "      <td>f</td>\n",
       "      <td>53</td>\n",
       "      <td>16.0</td>\n",
       "      <td>library staff</td>\n",
       "      <td>1517</td>\n",
       "      <td>577</td>\n",
       "      <td>[0, 6, 0, 6, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>1518</td>\n",
       "      <td>242</td>\n",
       "      <td>disable</td>\n",
       "      <td>874</td>\n",
       "      <td>[0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 2, 0, 1, 3, 0, ...</td>\n",
       "      <td>2021-08-28 13:04:57</td>\n",
       "      <td>2021-08-28 13:11:00</td>\n",
       "      <td>[3307, 4664, 2538, 4412, 4110, 8903, 5728, 233...</td>\n",
       "      <td>[1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, ...</td>\n",
       "      <td>8684799</td>\n",
       "      <td>A3S2R1NK6HZ9KP</td>\n",
       "      <td>f</td>\n",
       "      <td>36</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>1518</td>\n",
       "      <td>874</td>\n",
       "      <td>[0, 6, 0, 0, 6]</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1518 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  stim_id      stim  subject_id  \\\n",
       "0        1      294     imply           1   \n",
       "5        2      208      thaw           2   \n",
       "10       3       40   wriggle           3   \n",
       "15       4       57    arrive           4   \n",
       "20       5       22    cringe           5   \n",
       "...    ...      ...       ...         ...   \n",
       "317   1514      254  activate         872   \n",
       "865   1515       45     start         873   \n",
       "1238  1516       35      wail         645   \n",
       "672   1517       29     bathe         577   \n",
       "1161  1518      242   disable         874   \n",
       "\n",
       "                                               response                start  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, ...  2021-08-24 12:37:49   \n",
       "5     [0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, ...  2021-08-24 12:36:28   \n",
       "10    [3, 0, 0, 0, 1, 0, 1, 6, 6, 6, 3, 2, 1, 6, 0, ...  2021-08-24 12:47:34   \n",
       "15    [5, 0, 0, 0, 0, 0, 0, 4, 6, 4, 1, 0, 0, 6, 0, ...  2021-08-24 12:49:04   \n",
       "20    [3, 3, 0, 2, 0, 0, 1, 3, 6, 1, 1, 0, 2, 4, 1, ...  2021-08-24 13:23:42   \n",
       "...                                                 ...                  ...   \n",
       "317   [5, 3, 1, 2, 4, 4, 3, 1, 1, 2, 2, 1, 0, 2, 6, ...  2021-08-28 09:38:19   \n",
       "865   [6, 3, 6, 3, 2, 6, 2, 3, 3, 6, 3, 3, 6, 6, 3, ...  2021-08-28 09:44:10   \n",
       "1238  [1, 0, 1, 0, 0, 0, 0, 0, 5, 0, 1, 0, 5, 3, 0, ...  2021-08-28 10:18:07   \n",
       "672   [5, 0, 0, 0, 0, 0, 0, 1, 6, 2, 3, 0, 2, 5, 6, ...  2021-08-28 10:37:50   \n",
       "1161  [0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 2, 0, 1, 3, 0, ...  2021-08-28 13:04:57   \n",
       "\n",
       "                      end                                                 RT  \\\n",
       "0     2021-08-24 12:43:52  [5841, 1584, 1808, 2144, 2008, 2680, 3416, 114...   \n",
       "5     2021-08-24 12:49:54  [5114, 2594, 2164, 8210, 26407, 2706, 9729, 11...   \n",
       "10    2021-08-24 12:52:58  [4728, 1777, 1777, 1864, 11745, 2536, 4121, 47...   \n",
       "15    2021-08-24 13:00:17  [13362, 2288, 3391, 3672, 4813, 3144, 5584, 64...   \n",
       "20    2021-08-24 13:31:44  [7343, 3488, 3920, 7568, 2992, 3808, 4968, 636...   \n",
       "...                   ...                                                ...   \n",
       "317   2021-08-28 09:48:43  [3744, 2720, 2944, 5064, 5416, 10400, 4312, 44...   \n",
       "865   2021-08-28 10:01:13  [5328, 3789, 2640, 3636, 15144, 3160, 2187, 39...   \n",
       "1238  2021-08-28 10:32:48  [6088, 3116, 5168, 33664, 3972, 4848, 3268, 34...   \n",
       "672   2021-08-28 10:53:09  [4344, 2234, 2390, 9221, 20266, 128198, 21287,...   \n",
       "1161  2021-08-28 13:11:00  [3307, 4664, 2538, 4412, 4110, 8903, 5728, 233...   \n",
       "\n",
       "                                            buttonpress  turkcode  \\\n",
       "0     [2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, ...   7467737   \n",
       "5     [1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 2, 2, 1, 2, 1, ...   5481024   \n",
       "10    [2, 1, 1, 1, 2, 1, 1, 2, 1, 3, 1, 1, 3, 1, 1, ...   3663884   \n",
       "15    [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   1561528   \n",
       "20    [2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, ...   1183680   \n",
       "...                                                 ...       ...   \n",
       "317   [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, ...   7910923   \n",
       "865   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   6194369   \n",
       "1238  [1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, ...   6822510   \n",
       "672   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, ...   3616355   \n",
       "1161  [1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, ...   8684799   \n",
       "\n",
       "         subject_num gender  age  education  \\\n",
       "0      ADJ9I7ZBFYFH7      m   32       13.0   \n",
       "5     A3NKZMF7M4X0ZP      m   27       16.0   \n",
       "10    A2OG7XGWOX5ZEF      m   33       14.0   \n",
       "15    A170R0WAZC31WC      f   51       15.0   \n",
       "20     AAXX5LDVJ32F8      m   49       12.0   \n",
       "...              ...    ...  ...        ...   \n",
       "317    ALTSDQ7JAWE7E      f   39       16.0   \n",
       "865   A1N35VV9QURKHX      f   45       14.0   \n",
       "1238  A3O0ZQMDKOKAMR      f   44       12.0   \n",
       "672    A49A0FF6ZXYDU      f   53       16.0   \n",
       "1161  A3S2R1NK6HZ9KP      f   36       16.0   \n",
       "\n",
       "                                             occupation  results_id  \\\n",
       "0                              Security at a warehouse            1   \n",
       "5                                                   NaN           2   \n",
       "10    I work at a large retail store moving items an...           3   \n",
       "15              Variable data tech for print on demand            4   \n",
       "20                                           unemployed           5   \n",
       "...                                                 ...         ...   \n",
       "317   AR Specialist for my full time job and office ...        1514   \n",
       "865                            Information  Data Entry         1515   \n",
       "1238  I am a fulltime Decorator for a retail grocery...        1516   \n",
       "672                                       library staff        1517   \n",
       "1161                                       Data Analyst        1518   \n",
       "\n",
       "      catch_subject_id   catch_response  incorrectN badsubject  \n",
       "0                    1  [0, 6, 0, 6, 6]           0          N  \n",
       "5                    2  [0, 6, 0, 6, 6]           0          N  \n",
       "10                   3  [0, 6, 0, 6, 6]           0          N  \n",
       "15                   4  [0, 6, 0, 6, 6]           0          N  \n",
       "20                   5  [0, 6, 0, 6, 6]           0          N  \n",
       "...                ...              ...         ...        ...  \n",
       "317                872  [0, 6, 0, 6, 6]           0          N  \n",
       "865                873  [7, 6, 0, 6, 6]           0          N  \n",
       "1238               645  [0, 6, 0, 6, 6]           0          N  \n",
       "672                577  [0, 6, 0, 6, 6]           0          N  \n",
       "1161               874  [0, 6, 0, 0, 6]           1          N  \n",
       "\n",
       "[1518 rows x 20 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res_combined = pd.concat([res_all1, res_all2], ignore_index=True)\n",
    "# res_combined['id'] = list(range(1, res_combined.shape[0]+1))\n",
    "\n",
    "# print(res_all1.shape)\n",
    "# print(res_all2.shape)\n",
    "# print(res_combined.shape)\n",
    "# res_combined\n",
    "\n",
    "res_combined = merge_tables(b)\n",
    "res_combined\n",
    "\n",
    "##check whether there is a duplicate row\n",
    "duplicates = res_combined.duplicated()\n",
    "duplicates = duplicates.index[duplicates]\n",
    "len(duplicates)\n",
    "\n",
    "\n",
    "#### add lemma column\n",
    "stimr = pd.read_csv(path+b+'/'+'wro1_stimuli.txt', delimiter=\"\\t\")\n",
    "stim = stimr[stimr['id'].notna()][[\"id\", \"stim\"]].reset_index(drop=True).astype({\"id\": int})\n",
    "stim['stim'] = stim['stim'].str[:-1]\n",
    "stim.rename(columns={'id':'stim_id'}, inplace=True)\n",
    "stim\n",
    "\n",
    "res_combined = pd.merge(left=res_combined, right=stim, on=\"stim_id\").sort_values(by=\"id\")\n",
    "res_combined = rearrange_col(res_combined, 'stim', 'stim_id')\n",
    "res_combined\n",
    "\n",
    "\n",
    "##### mark bad subjects (updated)\n",
    "res_combined['catch_response_split'] = res_combined['catch_response'].apply(lambda x:x.split('_'))\n",
    "catch_series = res_combined['catch_response_split'].tolist()\n",
    "#correct_answer = [count_correct_answers(l) for l in catch_series]\n",
    "incorrect_answer = [count_incorrect_answers(l) for l in catch_series]\n",
    "res_combined['incorrectN'] = incorrect_answer\n",
    "\n",
    "res_combined.loc[res_combined['incorrectN']>=3, 'badsubject'] = 'Y'\n",
    "res_combined.loc[res_combined['incorrectN']<3, 'badsubject'] = 'N'\n",
    "res_bad = res_combined.loc[res_combined['badsubject']=='Y']\n",
    "print('# of bad subject:', res_bad.shape[0], 'out of', res_combined.shape[0])\n",
    "\n",
    "res_combined['response_split'] = res_combined['response'].apply(lambda x:x.split('_'))\n",
    "res_combined['RT_split'] = res_combined['rt'].apply(lambda x:x.split('_'))\n",
    "res_combined['buttonpress_split'] = res_combined['buttonpress'].apply(lambda x:x.split('_'))\n",
    "\n",
    "res_combined = rearrange_col(res_combined, \"response_split\", \"response\")\n",
    "res_combined = rearrange_col(res_combined, \"RT_split\", \"rt\")\n",
    "res_combined = rearrange_col(res_combined, \"buttonpress_split\", \"buttonpress\")\n",
    "\n",
    "for c in ['catch_response', 'response', 'rt', 'buttonpress']:\n",
    "    res_combined.drop(columns=[c], inplace=True)\n",
    "    \n",
    "res_combined.rename(columns={'catch_response_split': 'catch_response', 'response_split':'response', 'RT_split':'RT', 'buttonpress_split':'buttonpress'}, inplace=True)\n",
    "\n",
    "res_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export to csv\n",
    "#res_combined.to_csv(path+'results_clean_0813.csv', index=False)\n",
    "res_combined.to_csv(path+'results_catchreject_0831.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######to export bad subjects list\n",
    "df_bad = res_combined.loc[res_combined['badsubject']=='Y', ]\n",
    "df_bad.to_csv(path+'badsubjects_0831.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
